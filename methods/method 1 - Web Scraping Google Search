# Firstly, install the requests and BeautifulSoup libraries using pip if haven't. Install them with the following command: pip install requests beautifulsoup4

import requests
from bs4 import BeautifulSoup
import openpyxl

def google_search(query):
    url = f"https://www.google.com/search?q={query} address"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')
    address_element = soup.find("div", class_="BNeawe iBp4i AP7Wnd")
    address = address_element.get_text() if address_element else "Address not found"
    return address

# Load Excel file
excel_file_path = "company_names.xlsx"
wb = openpyxl.load_workbook(excel_file_path)
sheet = wb.active

for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row, min_col=1, max_col=1):
    company_name = row[0].value
    address = google_search(company_name)
    row[0].offset(column=1).value = address

# Save Excel file with addresses
wb.save("company_addresses.xlsx")
